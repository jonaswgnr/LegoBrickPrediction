{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import *\n",
    "\n",
    "# image processing\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# build your own nets\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_files_path = \"Data/brickImages/train\"\n",
    "valid_image_files_path = \"Data/brickImages/valid\"\n",
    "test_image_files_path = \"Data/brickImages/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11214 Bush 3M friction with Cross axle\n"
     ]
    }
   ],
   "source": [
    "brick_list = [ '11214 Bush 3M friction with Cross axle','3004 Brick 1x2','3024 Plate 1x1','3673 Peg 2M', \n",
    "              '18651 Cross Axle 2M with Snap friction','3005 Brick 1x1','3040 Roof Tile 1x2x45deg','3713 Bush for Cross Axle',\n",
    "              '2357 Brick corner 1x2x2','3022 Plate 2x2','3069 Flat Tile 1x2','3794 Plate 1X2 with 1 Knob','3003 Brick 2x2',\n",
    "              '3023 Plate 1x2','32123 half Bush','6632 Technic Lever 3M' ]\n",
    "\n",
    "print(brick_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6379 images belonging to 16 classes.\n",
      "Found 6379 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(train_image_files_path + \"/\" + brick_list[0] + \"/201706171006-0001.png\")\n",
    "img_width, img_height = im.size\n",
    "\n",
    "output_n = len(brick_list)\n",
    "size = 50\n",
    "channels = 3\n",
    "batch_size = 16\n",
    "\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale = 1 / 255,\n",
    "    rotation_range = 40,\n",
    ")\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(\n",
    "    # validation data shouldn't be augmented\n",
    "    rescale = 1 / 255\n",
    ")\n",
    "\n",
    "train_image_array_gen = train_data_gen.flow_from_directory(\n",
    "    train_image_files_path,\n",
    "    target_size = (img_width, img_height),\n",
    "    class_mode = 'categorical',\n",
    "    classes = brick_list,\n",
    "    color_mode = 'rgb', \n",
    "    batch_size = batch_size,\n",
    "    seed = 42)\n",
    "\n",
    "valid_image_array_gen = valid_data_gen.flow_from_directory(\n",
    "    valid_image_files_path,\n",
    "    target_size = (img_width, img_height),\n",
    "    class_mode = 'categorical',\n",
    "    classes = brick_list,\n",
    "    color_mode = 'rgb', \n",
    "    batch_size = batch_size,\n",
    "    seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6379 6379\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 198, 198, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 198, 198, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 198, 198, 32)      18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 198, 198, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 198, 198, 16)      4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 198, 198, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 198, 198, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 99, 99, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 99, 99, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 156816)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               80290304  \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 80,323,840\n",
      "Trainable params: 80,323,616\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "train_samples = train_image_array_gen.n\n",
    "valid_samples = valid_image_array_gen.n\n",
    "print(train_samples, valid_samples)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding = \"valid\", input_shape = (img_width, img_height, channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.5))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding = \"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.5))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.125))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(output_n))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = RMSprop(lr = 0.0001, decay = 1e-6),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 18/398 [>.............................] - ETA: 3:49:46 - loss: 12.1747 - acc: 0.1701"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_image_array_gen,\n",
    "    steps_per_epoch = int(train_samples / batch_size), \n",
    "    epochs = epochs, \n",
    "    validation_data = valid_image_array_gen,\n",
    "    validation_steps = int(valid_samples / batch_size),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd test_image_files_path && wget https://images-na.ssl-images-amazon.com/images/I/512rSmEUxBL._SL1001_.jpg\n",
    "\n",
    "test_images = !find $test_image_files_path -type f -name \"*.jpg\"\n",
    "\n",
    "def classify_image_model(image, classes=classes):\n",
    "    img = cv2.imread(image)        \n",
    "    b,g,r = cv2.split(img)       \n",
    "    img = cv2.merge([r,g,b])     \n",
    "    plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    image = image_utils.load_img(image, target_size=(img_width, img_height))\n",
    "    image = image_utils.img_to_array(image)\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # scale pixels between -1 and 1, sample-wise\n",
    "    image /= 255.\n",
    "        \n",
    "    prediction = model.predict(image)\n",
    "    \n",
    "    pred = prediction.argmax()\n",
    "\n",
    "    for k, v in classes.items():\n",
    "        if (v == pred):\n",
    "            pred_label = k\n",
    "        \n",
    "    proba = prediction.max()\n",
    "    \n",
    "    print(\"Predicted class: \" + pred_label + \" with probability \" + str(proba*100) + \"%\")\n",
    "\n",
    "print(test_images[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
